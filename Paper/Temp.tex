\documentclass[journal]{IEEEtran}
\usepackage{graphicx}   
\usepackage{subcaption} 
\captionsetup{font=footnotesize}
\usepackage{stfloats} 
\usepackage{amsmath}  
\usepackage{amsfonts} 
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{multirow}
\usepackage{makecell}
\usepackage{bm}       
\usepackage{booktabs}
\usepackage{afterpage}
\usepackage{enumitem}
\usepackage{lettrine}
\usepackage{svg}
\newtheorem{remark}{Remark}
\newtheorem{definition}{Definition}
\newtheorem{proposition}{Proposition}
\begin{document}

\title{MOCHA: Motion Camouflage-Based Homotopy-Aware Trajectory Planning}
\author{
    Jianqing Li, Hechao Zhang, and Zhaohui Song
    \thanks{
        Jianqing Li is with the Space Information Research Institute and Zhejiang Key Laboratory of Space Information Sensing and Transmission, Hangzhou Dianzi University, Hangzhou, 310018, China.

        Hechao Zhang was with the Department of Communication Engineering, Hangzhou Dianzi University, Hangzhou, Zhejiang 310018, China. e-mail: a0823bbdd@163.com



        Zhaohui Song is with the Space Information Research Institute and Zhejiang Key Laboratory of Space Information Sensing and Transmission, Hangzhou Dianzi University, Hangzhou, 310018, China.
    }
}
\maketitle

%摘要
\begin{abstract}
Trajectory planning for multi-agent systems in dynamic and complex environments is a significant challenge. Planning speed is often constrained by the high-dimensional and large-scale nature of the optimization problem, while non-convex optimization is highly susceptible to local minima, leading to reduced motion efficiency and safety. This paper introduces a novel trajectory planning framework, MOCHA (Motion Camouflage-Based Homotopy-Aware Trajectory Planning). Inspired by the motion camouflage phenomenon in nature, MOCHA uses a novel reparameterization method that transforms high-dimensional intermediate waypoints into a sequence of one-dimensional scalar parameters, thereby significantly reducing the decision dimensionality. The framework also integrates a multi-homotopy front-end path search module to suppress local minima, utilizing H-signature to distinguish topologically different path classes. For dynamic environments, a local replanning module based on 3D spatiotemporal projections is further proposed. In both simulation and real-world experiments, we demonstrate that this method substantially increases computation speed while ensuring the agents' motion efficiency and safety.
\end{abstract}

%关键词
\begin{IEEEkeywords}
Multi-agent systems, trajectory planning, homotopy awareness, motion camouflage, nonconvex optimization
\end{IEEEkeywords}

%正文
\section{Introduction}
\lettrine{A}{chieving} safe and flexible trajectory planning in complex environments remains a central challenge for aerial and ground robots, requiring planners to satisfy kinodynamic feasibility, collision avoidance, and smoothness under onboard real-time constraints~\cite{Gao2020FASTER,Wang2022GCOPTER}. The difficulty escalates in multi-agent systems due to coupling between agents, uncertainty propagation, and communication limitations~\cite{Luis2020RAL,Kondo2023RMADER}. These systems must generate dynamically feasible trajectories and update them frequently to accommodate changes in the environment or the behavior of neighboring agents.
%\begin{figure}[t]
    %\centering
    %\includegraphics[trim=140 10 120 20, clip,width=1.0\linewidth]{Figure/robot.png}
    %\caption{Candidate trajectories optimized by the MOCHA framework %running on real-world robots.}
    %\label{fig:robot}
%\end{figure}
Optimization-based planners have shown strong performance by leveraging differential flatness and polynomial parameterizations to encode dynamics and smoothness~\cite{Ratliff2009CHOMP,Kalakrishnan2011STOMP,Schulman2014TrajOpt}. However, the dimensionality of decision variables grows rapidly with the number of trajectory segments and agents. This amplifies the nonconvexity of the problem and causes computation latency to scale poorly, threatening responsiveness when replanning is required at high frequency~\cite{Mukadam2018GPMP2,Hauser2015RSS}.

Beyond scalability, nonconvex optimization is highly sensitive to initialization and often converges to undesired local minima when multiple homotopy classes exist~\cite{Bhattacharya2010AAAI,Bhattacharya2011RSS}. Recent work combines global structure with local optimization to alleviate this issue by enumerating distinct homotopy routes~\cite{DeGroot2025TMPC}, or constructing safe corridors from perception or search~\cite{Gao2020FASTER,Zhou2021EGOPlanner}. Yet, accurate homotopy reasoning in space–time remains costly, and naive multi-start strategies struggle with real-time operation.

To address these challenges, we propose MOCHA, a framework that introduces a geometry-inspired reparameterization to reduce trajectory dimensionality and integrates homotopy-aware multi-candidate optimization for robustness in complex, dynamic scenes. The design naturally extends to distributed coordination, where each agent asynchronously shares minimal trajectory descriptors~\cite{Luis2020RAL,Kondo2023RMADER}, preserving scalability without sacrificing safety.

The contributions of this article are as follows:

1) A new reparameterization technique, inspired by motion camouflage, is presented. It converts the complex waypoint optimization problem into the task of optimizing a sequence of scalars for each trajectory segment. This approach maintains geometric interpretability while facilitating efficient gradient flow through the simplified representation.

2) We introduce an integrated, homotopy-aware planning framework that can manage both dynamic obstacles and the coordination of multiple agents. It combines a lightweight frontend planner with diverse topological options and an optimization backend that maintains structural integrity, utilizing a spatiotemporal homotopy approximation. This system naturally extends to distributed multi-agent systems through an asynchronous trajectory commitment process.

3) We develop an efficient local replanning module that perturbs only a short sliding time window of the current plan to avoid predicted dynamic obstacles and then smoothly rejoin the global trajectory at an anchor point. This targeted modification significantly cuts solve time and latency while preserving feasibility and consistency with the global plan. A simple check ensures that a full global replan is only triggered if the conflict extends beyond this window or feasibility is severely violated.

\section{Related Work}
\subsection{Trajectory Planning}
Two predominant paradigms address kinodynamically feasible trajectory planning: sampling-based search and trajectory optimization. 
Sampling-based planners, such as $\text{FMT}^\ast$ and $\text{BIT}^\ast$~\cite{Janson2015FMT,Gammell2020BITstar,Orthey2024SamplingReview}, exploit random geometric structures to scale exploration in cluttered environments. 
Geometric sampling-based planners (e.g., $\text{RRT}^\ast$~\cite{Karaman2011RRTstar}) typically produce a geometry-only path that is subsequently time-parameterized to satisfy kinodynamic limits. 
By contrast, $\text{SST}/\text{SST}^\ast$~\cite{Li2016SST} and kinodynamic $\text{RRT}^\ast$ variants~\cite{webb2013kinodynamic} reason directly in the state space and therefore do not require a separate retiming step; however, under high-frequency replanning and strong actuation constraints they can still suffer from temporal consistency and responsiveness issues.

Optimization-based approaches instead encode smoothness, dynamic limits, and obstacle clearance directly in the cost formulation. 
Representative methods such as CHOMP/STOMP~\cite{Ratliff2009CHOMP,Kalakrishnan2011STOMP} and frameworks like TrajOpt~\cite{Schulman2014TrajOpt} and GPMP2~\cite{Mukadam2018GPMP2} exploit differentiability and sparse structure for efficient gradient-based refinement. 
Convex relaxation through safe corridors or polytopic approximations (e.g., IRIS, Bézier convex hull)~\cite{Deits2015IRIS,Gao2020FASTER} further improves safety guarantees, and GCS-based relaxations~\cite{Marcucci2023SciRob} yield tight convex relaxations with global optimality certificates under idealized assumptions.
For aerial robots, approaches such as time-optimal retiming (e.g., TOPPRA~\cite{Pham2017TOPPRA}), robustness-oriented trajectory optimization in clutter~\cite{Hauser2015RSS}, MINCO/GCOPTER, and ESDF-free optimization have achieved fast onboard performance.

However, these optimization-based planners remain highly sensitive to initialization and the scale of the decision space. 
Their efficiency relies heavily on the quality of the initial path provided by a front-end module, and waypoint-dense parameterizations aggravate nonconvexity, resulting in dimensionality issues, degraded gradient flow, and a high risk of local minima. 
Consequently, supporting global-scale planning and real-time replanning simultaneously remains challenging, motivating the need for stronger topological guidance and lower-dimensional parameterizations that stabilize convergence while reducing computational cost.

\subsection{Homotopy-Aware Planning and Local Minima}
When obstacles induce multiple feasible homotopy classes, gradient-based solvers can easily converge to locally valid but globally suboptimal trajectories. To overcome this, early studies introduced homology and $H$-signature representations~\cite{Bhattacharya2010AAAI,Bhattacharya2011RSS} to classify trajectories into distinct topological classes and to diversify optimization seeds. Subsequent systems extend this idea by optimizing multiple candidates in parallel across different homotopy classes~\cite{DeGroot2025TMPC}, effectively improving robustness to local minima. Skeleton-based reasoning and corridor decomposition methods also reduce the dimensionality of topological representations, improving computational tractability. 

Nevertheless, accurate homotopy classification in high-dimensional or time-varying spaces is computationally expensive, and naive multi-start strategies quickly become infeasible for real-time operation. 
Recent advances ~\cite{DeGroot2025TMPC} have incorporated spatiotemporal reasoning by embedding time as an additional dimension, enabling planners to handle moving obstacles as static entities in a high-dimensional configuration space. Although this improves adaptability to dynamic environments, it significantly increases computational burden. 
This limitation motivates the use of practical, lightweight homotopy proxies that preserve class distinction while minimizing labeling and optimization cost. In this work, we adopt this direction by extending classical $H$-signature reasoning with an efficient 3D spatiotemporal projection to approximate topological distinctions in dynamic scenes.

\subsection{Planning in Dynamic and Multi-Agent Environments}  
Multi-robot trajectory planning involves managing collision avoidance, reciprocal anticipation, and communication constraints among different agents~\cite{VanDenBerg2011ORCA}. Early approaches often relied on centralized optimization, such as model predictive control (MPC) formulations~\cite{Luis2020RAL}, which ensure global consistency but scale poorly with the number of agents and communication load. Their dependence on centralized computation makes them unsuitable for dynamic environments that demand rapid replanning and responsiveness. 

In contrast, single-robot high-speed replanning frameworks such as FASTER~\cite{Gao2020FASTER} and Ego-Planner~\cite{Zhou2021EGOPlanner} demonstrate strong adaptability to dynamic obstacles through perception–planning co-design and continuous optimization. However, these methods operate on a single platform and therefore lack the coordination mechanisms required in multi-agent scenarios. 

To improve scalability and flexibility, decentralized and asynchronous planning frameworks such as ORCA~\cite{VanDenBerg2011ORCA}, DMPC~\cite{Luis2020RAL}, and RMADER~\cite{Kondo2023RMADER} allow each agent to plan locally while maintaining safety through limited inter-agent communication. This distributed structure significantly reduces coupling and computational load, enabling multi-agent systems to operate effectively in dynamic and communication-limited environments. 

Despite these advantages, frequent local replanning can still cause deviations from globally consistent trajectories and increase computational overhead due to continuous full-trajectory optimization. To mitigate these issues, this work adopts a distributed multi-agent planning scheme incorporating a sliding time-window mechanism. Each agent performs only minor local adjustments within a short temporal horizon and triggers global replanning only when deviations exceed this window, maintaining smooth trajectories, predictable latency, and coherence with the overall plan.

\section{Preliminaries and Problem Formulation}
\subsection{Differential Flatness and Trajectory Representation}
\label{subsec:flatness}
Consider a general nonlinear \emph{control-affine} system
\begin{equation}
    \dot{\mathbf{x}} = f(\mathbf{x}) + g(\mathbf{x})\mathbf{u}.
\end{equation}
The system is \emph{differentially flat} if there exists a flat output $\mathbf{z}$ and smooth mappings $\Psi_x,\Psi_u$ such that
\begin{align}
    \mathbf{x} &= \Psi_x(\mathbf{z},\dot{\mathbf{z}},\ldots,\mathbf{z}^{(s-1)}), \\
    \mathbf{u} &= \Psi_u(\mathbf{z},\dot{\mathbf{z}},\ldots,\mathbf{z}^{(s)}).
\end{align}
For multicopters, a widely adopted flat output is
\begin{equation}
    \mathbf{z} = (p_x, p_y, p_z, \psi)^\top
\end{equation}
where $(p_x,p_y,p_z)^\top$ denotes the position of the center of mass and $\psi$ the yaw angle. 

Building on \emph{differential flatness}, MINCO~\cite{Wang2022GCOPTER} introduces an efficient parameterized trajectory representation. For a given flat output $\mathbf{z}(t)$, it formulates the problem of a constrained minimum control effort as follows
\begin{equation}
\begin{aligned}
    \min_{\mathbf{z}(t), T} \quad
    & J = \int_0^T  \lVert \mathbf{z}^{(s)}(t)\rVert^2\,dt  \\
\end{aligned} \label{eq:minco_cost}
\end{equation}
and shows that, given a fixed set of segment durations, boundary derivatives up to order $s-1$ and specified intermediate knots, there exists a unique optimal solution, which takes the form of a piecewise polynomial of degree $2s-1$.

This result enables efficient spatiotemporal decoupling: the piecewise polynomial over $M$ segments is parameterized by intermediate waypoints $\mathbf{q}=(\mathbf{q}_1,\dots,\mathbf{q}_{M-1})$ and durations $\boldsymbol{\tau}=(\tau_1,\dots,\tau_M)^\top$, while the polynomial coefficients $\mathbf{c}$ can be directly constructed with linear complexity $O(M)$ by solving a nonsingular banded system:
\begin{equation}
    \mathbf{A}(\boldsymbol{\tau})\,\mathbf{c}(\mathbf{q},\boldsymbol{\tau}) = \mathbf{b}(\mathbf{q})
\label{eq:minco_system}
\end{equation}

Then we can address the original problem that involves complex constraints. Leveraging \emph{differential flatness}, requirements such as dynamic feasibility and obstacle avoidance are transformed into the flat output space. Since the trajectory is parameterized, these constraints are then handled by optimizing over the parameter space$\{\mathbf{q},\boldsymbol{\tau}\}$. Constraint elimination techniques are used to ultimately reformulate the problem as an unconstrained optimization.

\subsection{Motion Camouflage Principle}
\label{subsec:motion_camouflage}

\emph{Motion camouflage} is a strategy observed in nature, where a predator moves towards its prey in such a manner that it appears to remain stationary from the prey's perspective against a distant background \cite{Srinivasan1995StrategiesFA}. This illusion is achieved by constraining the predator’s movement to follow a specific path. Specifically, its bearing is restricted to a fixed line, known as the \textbf{camouflage line}, which continuously connects the prey and a selected stationary reference point. The relative motion relationships and the geometric principle of this phenomenon are illustrated in Fig.~\ref{fig:mc}.

\begin{figure}[tbp]
    \centering
    \includegraphics[trim=0 30 15 45, clip, width=0.75\linewidth]{Figure/prey.pdf} 
    \caption{Illustration of the motion camouflage phenomenon. The light green line represents the virtual prey trajectory ($p_{\text{prey}}$), while the different cyan lines (predator 1, 2, 3) represent different actual trajectories generated by adjusting the one-dimensional control parameter ($\lambda$). All points on the trajectories lie on the "camouflage line" connecting the reference point ($p_{\text{ref}}$) and the corresponding points on the prey's trajectory.}
    \label{fig:mc}
\end{figure}

The geometric relationship among the predator's position $\mathbf{p}_{\text{predator}}$, the prey's position $\mathbf{p}_{\text{prey}}$, and the reference point $\mathbf{p}_{\text{ref}}$ can be mathematically formulated as \cite{Li2025Camouflage}:
\begin{equation} 
\mathbf{p}_{\text{predator}} = \mathbf{p}_{\text{ref}} + \lambda (\mathbf{p}_{\text{prey}} - \mathbf{p}_{\text{ref}})
\label{eq:mc}
\end{equation}
where $\lambda$ is a one-dimensional path control parameter. The value of $\lambda$ dictates the predator's position along the camouflage line. In particular, when $\lambda=1$, the positions of predator and prey coincide, signifying a successful interception \cite{Li2025Camouflage}. By manipulating the parameter $\lambda$ and the location of $\mathbf{p}_{\text{ref}}$, a wide array of trajectories can be generated, forming the theoretical basis for our proposed dimensionality reduction method.

\subsection{Problem Formulation}
\label{subsec:problem_formulation}
We consider $N$ agents collaboratively executing tasks in a $d$-dimensional workspace $\mathcal{W}\subseteq\mathbb{R}^d$ with $d\in\{2,3\}$.  As established in Sec.~\ref{subsec:flatness}, all agents considered here are \emph{differentially flat}. For each agent $\varkappa$, we optimize the translational flat-output vector $\mathbf{p}(t)$ and its derivatives up to order $s$. This simplification is justified as the yaw component, $\psi(t)$, is largely decoupled from the translational dynamics and can be planned separately, which significantly reduces the dimensionality. 

We assume a cluttered, dense environment containing static and dynamic obstacles represented by closed sets $\mathcal{O}_{\text{stat}}\subset\mathcal{W}$ and $\mathcal{O}_{\text{dyn}}(t)\subset\mathcal{W}$, respectively. Let $\mathcal{F}(t)\subseteq\mathcal{W}$ denote the obstacle-free region available to the agent at time $t$.

The task is to generate a trajectory $\mathbf{p}(t)$ that is smooth, dynamically feasible, and collision-free. Following the principles of optimal control, we formulate the trajectory planning problem for each agent as a continuous-time constrained optimization problem that minimizes a weighted sum of control effort and flight duration. The problem is formally stated as:
\begin{equation}
\begin{aligned}
    \min_{\mathbf{p}(t), T} \quad
    & J = \int_{0}^{T} \lVert \mathbf{p}^{(s)}(t)\rVert^2 \, dt + \rho \cdot T \\
    \text{s.t.} \quad
    &\mathbf{p}^{(0:s-1)}(0) = \bar{\mathbf{p}}_0, \\
    &\mathbf{p}^{(0:s-1)}(T) = \bar{\mathbf{p}}_f, \\
    &\mathcal{H}(\mathbf{p}(t), \dots, \mathbf{p}^{(s)}(t)) \le 0, \ \forall t \in [0, T].
\end{aligned} \label{eq:prob_formulation_multi_agent}
\end{equation}
Here, $\mathbf{p}^{(0:s-1)}(t)
= \big( \mathbf{p}^{\top}(t), \dot{\mathbf{p}}^{\top}(t), \ldots, \mathbf{p}^{(s-1)\top}(t) \big)^{\top}$ denotes the stacked flat state up to order $s-1$. The boundary conditions $\bar{\mathbf{p}}_0$ and $\bar{\mathbf{p}}_f$ define the fixed initial and terminal states, $\rho$ is the time regularization parameter, and $T$ denotes the total trajectory duration.

The term $\mathcal{H}(\cdot)$ encapsulates the set of continuous-time inequality constraints that are the primary source of complexity in multi-agent planning. These constraints include:
\begin{enumerate}
    \item Obstacle Avoidance: The position $\mathbf{p}(t)$ must remain within the defined obstacle-free region for all time.
    \item Inter-Agent Collision Avoidance: A minimum safe distance $d_s$ must be maintained between any pair of agents.
    \item Dynamic Feasibility: The magnitudes of velocity and acceleration are constrained by the physical limits of the vehicle, $v_{\max}$ and $a_{\max}$.  These are expressed as constraints on the derivatives of the trajectory, i.e., $\lVert \dot{\mathbf{p}}(t) \rVert^2 \le v_{\max}^2$ and $\lVert \ddot{\mathbf{p}}(t) \rVert^2 \le a_{\max}^2$.
\end{enumerate}

As discussed in Sec.~\ref{subsec:flatness}, we can use a compact, sparse parameterization to solve this optimization problem. However, as the number of agents $N$ and the segment count per trajectory grow, this increase leads to slower solve times. Therefore, we introduce a novel and more efficient parameterization in the next section.

\section{THE PROPOSED MOCHA METHOD}
Before delving into the technical details of our approach, we first provide an overview of the MOCHA framework's structure and workflow, which is divided into Global Planning and Local Replanning modules, as illustrated in Fig.~\ref{fig:system}.

\begin{figure*}[tbp]
    \centering
    \includegraphics[trim=24 119 27 34,clip, width=0.8\linewidth]{Figure/system.pdf}
    \caption{System architecture of the MOCHA framework. The system comprises two main components: \textbf{(a) MOCHA Global Planning}, which utilizes a Homotopy-Aware front-end (Apollonius/PRM and H-signature) to generate multiple topologically distinct path candidates, followed by the Motion Camouflage Reparameterization and Trajectory Optimization to select the lowest-cost trajectory. \textbf{(b) MOCHA Local Replanning}, which incorporates time into the state space for Spatiotemporal Topology search (using PRM and H-signature approximation) and then employs the same efficient Motion Camouflage Reparameterization and Optimization modules for rapid dynamic obstacle avoidance and smooth return to the global path.}
    \label{fig:system}
\end{figure*}

\label{sec:global_planner}
\subsection{Motion Camouflage Reparameterization}
The MINCO framework transforms the trajectory optimization problem described in \eqref{eq:prob_formulation_multi_agent} into a sparse parameter optimization at intermediate waypoints $\mathbf{q}\in\mathbb{R}^{d\times(M-1)}$ and segment durations $\boldsymbol{\tau}$. However, the high dimensionality of the intermediate waypoints can still become a significant bottleneck. Specifically, a large number of decision variables rapidly amplifies the non-convexity of the objective function, increasing the risk of convergence to undesired local minima, and simultaneously causes the computation latency of gradient-based solvers to scale poorly, thus threatening the real-time responsiveness required for frequent replanning.

To overcome this limitation and further accelerate computation, we draw inspiration from the motion camouflage principle to propose a novel reparameterization. Optimization-based algorithms often rely on an initial path provided by a front-end planner. We use this path as the virtual prey path $\mathbf{p}_{\text{prey}}$, and by selecting an additional reference point $\mathbf{p}_{\text{ref}}$, we reduce the high-dimensional waypoints $\mathbf{q}$ to a sequence of one-dimensional scalar parameters.

Specifically, the position $\mathbf{q}_k$ of each intermediate knot $k \in \{1, \dots, M-1\}$ is now defined by a scalar parameter $\lambda_k$:
\begin{equation}
    \mathbf{q}_k = \mathbf{p}_{\text{ref}} + \lambda_k (\mathbf{p}_{\text{prey}}(k) - \mathbf{p}_{\text{ref}}),
    \label{eq:q_lambda_relation}
\end{equation}
where $\mathbf{p}_{\text{prey}}(k)$ is the position on the virtual prey path corresponding to the $k$-th knot. The selection strategy for the reference point $\mathbf{p}_{\text{ref}}$ and its resulting influence on the state space are significant, especially the choice of direction. Therefore, our prior work \cite{Li2025Camouflage} investigated this selection strategy in depth. As illustrated in Fig.~\ref{fig:pref}, the position is determined based on a right-angled triangle formed by the line connecting the start and end points, while the direction is chosen towards the side with sparser obstacle distribution density to enhance optimization flexibility.

\begin{figure}[tbp]
\centering
\includegraphics[trim=25 18 10 30, clip,width=0.7\linewidth]{Figure/Pref.pdf}
\caption{Strategy for selecting the reference point $\mathbf{p}_{\text{ref}}$. The position is based on a right-angled triangle formed by the start-end line, and the direction is selected towards the side with lower obstacle density to enhance optimization flexibility.}
\label{fig:pref}
\end{figure}

In this method, the path $\mathbf{p}(t)$ is described as a piecewise polynomial of degree $2s-1$ across $M$ distinct segments. Optimization is carried out over the prey path parameters $\boldsymbol{\lambda}=(\lambda_1,\dots,\lambda_{M-1})$ and segment durations $\boldsymbol{\tau} = (\tau_1,\dots,\tau_{M})^\top$. The polynomial coefficients $\mathbf{c}=(\mathbf{c}_1^\top,\dots,\mathbf{c}_M^\top)^\top$ are directly constructed by solving
\begin{equation}
    \mathbf{A}(\boldsymbol{\tau})\mathbf{c}(\boldsymbol{\lambda},\boldsymbol{\tau}) = \mathbf{b}(\boldsymbol{\lambda}).
    \label{eq:lambda_system}
\end{equation}
The $i$-th segment trajectory is expressed as
\begin{equation}
    \mathbf{p}_i(t) = \mathbf{c}_i^\top \boldsymbol{\beta}(t),
    \qquad t\in[0,\,\tau_i),
    \label{eq:piecewise_p}
\end{equation}
where $\boldsymbol{\beta}(t)=(1, t, t^2, \dots, t^{(2s-1)})^\top$ denotes the polynomial basis, $\mathbf{c}_i\in\mathbb{R}^{(2s)\times d}$ is the $i$-th segment coefficient matrix.

This reparameterization substantially decreases the number of decision variables and endows them with a clear physical interpretation: $\boldsymbol{\lambda}$ implies the magnitude of the trajectory's deviation from the virtual prey path at the corresponding knot.

We have thus reformulated the trajectory optimization problem into a lower-dimensional and more structured parameter space, paving the way for scalable, real-time navigation for multi-agent systems.

\subsection{Problem Reformulation}
To efficiently solve the constrained trajectory optimization problem presented in \eqref{eq:prob_formulation_multi_agent}, we reformulate it into an unconstrained nonlinear program. This is achieved by first parameterizing the trajectory $\mathbf{p}(t)$ using our proposed method, where the decision variables are reduced to the one-dimensional scalar sequence $\boldsymbol{\lambda}$ and the segment durations $\boldsymbol{\tau}$.

Since $\boldsymbol{\lambda}$ and $\boldsymbol{\tau}$ are constrained, we introduce $\mathcal{C}^1$ bijective maps from unconstrained variables. Specifically, we optimize over two unconstrained variables, $\boldsymbol{\eta} \in \mathbb{R}^{M}$ for time and $\boldsymbol{\xi} \in \mathbb{R}^{M-1}$ for space.

For the temporal parameters, each segment duration $\tau_i$ is mapped from an unconstrained variable $\eta_i$ using a piecewise smooth function $\Psi(\cdot)$ that guarantees positivity:
\begin{equation}
    \tau_i = \Psi(\eta_i) = 
    \begin{cases}
        (\frac{1}{2} \eta_i + 1.0) \eta_i + 1.0, & \text{if } \eta_i > 0 \\
        \frac{1}{(\frac{1}{2} \eta_i - 1)\eta_i + 1} , & \text{if } \eta_i \le 0
    \end{cases}.
\end{equation}
For the spatial parameters, each scalar $\lambda_k$ is mapped from an unconstrained variable $\xi_k$ using a scaled logistic function, which bounds its value within a predefined range $(\lambda_{\min}, \lambda_{\max})$:
\begin{equation}
    \lambda_k = \Phi(\xi_k) = \lambda_{\min} + (\lambda_{\max} - \lambda_{\min}) \cdot \sigma(\xi_k),
\end{equation}
where $\sigma(\xi_k) = 1 / (1 + e^{-\xi_k})$ is the logistic function.

Subsequently, by sampling a fixed number of points within each trajectory segment, all continuous-time inequality constraints $\mathcal{H}(\cdot)$ are transcribed into the objective function as penalty terms. The final optimization problem is thus stated as:
\begin{equation}
    \min_{\boldsymbol{\xi}, \boldsymbol{\eta}} \quad J_{\text{total}} = w_e J_e + w_t J_t + J_p,
    \label{eq:unconstrained_problem}
\end{equation}
where $w_e$ and $w_t$ are positive weights, $J_e$ denotes control effort, $J_t$ is the total flight time $T=\sum_{i=1}^{M}\tau_i$, and $J_p$ includes dynamic feasibility limits, static obstacle avoidance, and inter-agent collision avoidance.
By solving this NLP problem, we can efficiently generate trajectories that are smooth, dynamically feasible, and collision-free.

\subsection{General Cost Function and Gradient Propagation}
\label{subsec:general_cost_gradient}
The MINCO framework provides an efficient method to map gradients of any cost functional $J^*$ from the space $(\mathbf{c},\boldsymbol{\tau})$ to the waypoint–time space $(\mathbf{q},\boldsymbol{\tau})$. We denote the resulting gradients by $\partial J^*/\partial \mathbf{q}$ and $\partial J^*/\partial \boldsymbol{\tau}$.

Our motion-camouflage reparameterization inserts one additional layer into this chain: the optimization variables are the scalars $\boldsymbol{\lambda}$ instead of $\mathbf{q}$. From \eqref{eq:q_lambda_relation},
\begin{equation}
\frac{\partial \mathbf{q}_k}{\partial \lambda_k} = (\mathbf{p}_{\text{prey}}(k) -\mathbf{p}_{\text{ref}})
\end{equation}
and by the chain rule the gradient with respect $\boldsymbol{\lambda}$ to is the vector–Jacobian product
\begin{equation}
    \frac{\partial J^*}{\partial \lambda_k} = \frac{\partial J^*}{\partial \mathbf{q}_k} \cdot \frac{\partial \mathbf{q}_k}{\partial \lambda_k}
\end{equation}
The gradient with respect to the segment durations passes through unchanged.

Finally, optimization is carried out in the unconstrained variables
$\boldsymbol{\xi}$ and $\boldsymbol{\eta}$. Applying the chain rule yields
\begin{align}
\frac{\partial J^*}{\partial \xi_k}
&= \frac{\partial J^*}{\partial \lambda_k}\,\Phi'(\xi_k), 
\qquad k=1,\ldots,M-1,\\
\frac{\partial J^*}{\partial \eta_i}
&= \frac{\partial J^*}{\partial \tau_i}\,\Psi'(\eta_i), 
\qquad i=1,\ldots,M.
\end{align}
where
\begin{align}
& \Phi'(\xi_k)=(\lambda_{\max}-\lambda_{\min})\,\sigma(\xi_k)\big(1-\sigma(\xi_k)\big),
\\
& \Psi'(\eta_i)=
\begin{cases}
\eta_i+1, & \eta_i>0,\\[4pt]
\dfrac{1-\eta_i}{\big(\tfrac12\eta^2_i-\eta_i+1\big)^2}, & \eta_i\le 0,
\end{cases}
\end{align}

This hierarchical gradient flow preserves the structured parameterization while keeping the overall computation efficient. 

Any time-integral penalty functional $J^*_p$ can be approximated by introducing a general penalty function $\mathcal{P}^*$ and sampling $\kappa+1$ points in each segment:
\begin{equation}
    J^*_p \approx \sum_{i=1}^{M} \frac{\tau_i}{\kappa} \sum_{j=0}^{\kappa} \omega_j\ \mathcal{P}^*(\mathbf{c}, \boldsymbol{\tau}, \alpha_j\tau_i),
\end{equation}
where $\omega_0=\omega_\kappa=\tfrac12$, $\omega_j=1$ for $j=1,\dots,\kappa-1$, and $\alpha_j = j / \kappa$. From \eqref{eq:piecewise_p}, we can form:
\begin{equation}
\begin{aligned}
    &\mathcal{P}^*(\mathbf{c}, \boldsymbol{\tau}, \alpha_j\tau_i) = \mathcal{P}^*\big(\,\mathbf{y}_i(\alpha_j\tau_i) \, , \tau^{(i,j)}_f\big),\\
    \text{s.t.} \quad
    &\tau^{(l,j)}_f=\sum_{m=1}^{l-1}\tau_m + \alpha_j\tau_l \\
    &\mathbf{y}_i(t) = \big( \mathbf{p}_i(t), \dots , \mathbf{p}^{(s-1)}_i(t) \big)
\end{aligned}
\end{equation}
If the constraints are independent of absolute time, the argument $\tau^{(l,j)}_f$ can be omitted. We then require the gradients of $J^*_p$ with respect to the polynomial coefficients $\mathbf{c}$ and the segment durations $\boldsymbol{\tau}$.

The gradient with respect to $c_i$ is given by the chain rule:
\begin{equation}
    \frac{\partial J^*_p}{\partial \mathbf{c}_i} = \frac{\tau_i}{\kappa}\sum_{j=0}^{\kappa} \omega_j\,
\frac{\partial \mathcal{P}^*}{\partial \mathbf{y}_i}\,
\frac{\partial \mathbf{y}_i}{\partial \mathbf{c}_i}
\end{equation}
where $\partial \mathbf{y}_i/{\partial \mathbf{c}_i}$ can be expressed using the derivatives of the polynomial basis $\boldsymbol{\beta}(t)$.

The gradient with respect to $\tau$ has two cases. If $\mathcal{P}^*$ does not depend on the absolute time:
\begin{equation}
\label{eq:tau_grad_timefree}
\frac{\partial J_p^*}{\partial \tau_i}
=
\frac{1}{\kappa}\sum_{j=0}^{\kappa} \omega_j\,\mathcal{P}^*
+\frac{\tau_i}{\kappa}\sum_{j=0}^{\kappa} \omega_j\,
\frac{\partial \mathcal{P}^*}{\partial \mathbf{y}_i}\,
\frac{\partial \mathbf{y}_i}{\partial t}\,\alpha_j,
\end{equation}
If $\mathcal{P}^*$ depends on absolute time, a perturbation of $\tau_i$ affects the current segment and all subsequent $l > i$. The sensitivity of the absolute time is:
\begin{equation}
    \frac{\partial \tau^{(l,j)}_f}{\partial \tau_i} =
    \begin{cases}
    \alpha_j,  &\text{if } l=i  \\ 
    1, &\text{if } l>i  \\ 
    0, &\text{if } l<i
    \end{cases}
\end{equation}
which yields the additional contribution
\begin{equation}
B = \sum_{l=i}^{M} \frac{\tau_l}{\kappa} \sum_{j=0}^{\kappa} \omega_j \frac{\partial \mathcal{P}^*}{\partial \tau^{(l,j)}_f} \frac{\partial \tau^{(l,j)}_f}{\partial \tau_i}
\label{eq:abs_time_term}
\end{equation}
The full gradient is the sum of \eqref{eq:tau_grad_timefree} and \eqref{eq:abs_time_term}.

\subsection{Specific Cost Function and Gradients}
This section will specify the concrete penalties; the gradients of the penalty functions and
the general gradient propagation from $(\mathbf{c},\boldsymbol{\tau})$ to $(\boldsymbol{\xi},\boldsymbol{\eta})$ follows Sec.\ref{subsec:general_cost_gradient}.

\textit{1) Control Effort $J_e$}: We sum the $s$-th control effort on each trajectory segment to obtain: 
\begin{equation}
\begin{aligned}
    J_e &= \sum_{i=1}^{M} \, \int_{0}^{\tau_i} \lVert \mathbf{p}_i^{(s)}(t) \rVert^2 \, dt \\
    &= \sum_{i=1}^{M} \, \text{tr} \left(\mathbf{c}^\top_i \left[\int_{0}^{\tau_i} \boldsymbol{\beta}^{(s)}(t)\boldsymbol{\beta}^{(s)\top}(t) dt\right] \mathbf{c}_i \right) \,.
\end{aligned}
\end{equation}
The gradients follow directly from the properties of quadratic forms and the Leibniz rule: 
\begin{align}
    \frac{\partial J_e}{\partial \mathbf{c}_i} &= 2\left( \int_{0}^{\tau_i} \boldsymbol{\beta}^{(s)}(t)\boldsymbol{\beta}^{(s)\top}(t) \, dt \right) \mathbf{c}_i\\[4pt]
    \frac{\partial J_e}{\partial \tau_i} &=\text{tr}\left(\mathbf{c}^\top_i \boldsymbol{\beta}^{(s)}(\tau_i)\boldsymbol{\beta}^{(s)\top}(\tau_i)\mathbf{c}_i\right)
\end{align}

\textit{2) Obstacle Avoidance $\mathcal{P}_o$}: We consider $R$ obstacles. To ensure collision-free motion, we define a penalty function that activates when the trajectory encroaches upon the safety margin of any obstacle:
\begin{align}
&\mathcal{P}_o\left(\mathbf{p}_i(t)\right) = \sum_{r=1}^R \phi\left(d^2_s - d_r^2(\mathbf{p}_i(t)\right)  \\
&\phi(x) = \max\{0,x\}^3
\end{align}
where $d_s$ is the prescribed safety distance and $d_r^2\left(\mathbf{p}_i(t)\right)$
is the squared minimum Euclidean distance from $\mathbf{p}_i(t)$ to obstacle $r$.

\textit{3) Dynamic Feasibility $\mathcal{P}_f$}: To ensure the trajectory respects the agent's physical limits, we take velocity and acceleration as examples and introduce a penalty as follows:
\label{eq:pf}
\begin{equation}
\begin{aligned}
\mathcal{P}_f(\mathbf{y}_i(t)) &= \mathcal{P}_v(\dot{\mathbf{p}}_i(t)) + \mathcal{P}_a(\ddot{\mathbf{p}}_i(t))\\[4pt]
\mathcal{P}_v(\dot{\mathbf{p}}_i(t)) &= \phi\left({\|\dot{\mathbf{p}}}_i(t)\|^2 - v_{\max}^2\right),\\[4pt]
\mathcal{P}_a(\ddot{\mathbf{p}}_i(t))&= \phi\left(\|\ddot{\mathbf{p}}_i(t)\|^2 - a_{\max}^2\right),\\[4pt]
\end{aligned}
\end{equation}

\textit{4) Inter-Agent Collision Avoidance $\mathcal{P}_s$}: To achieve scalable multi-agent navigation, we employ a distributed and asynchronous planning framework that does not rely on centralized computation. In this architecture, each agent broadcasts its current trajectory to neighboring agents as a "committed trajectory" during execution. Other agents then utilize these received broadcasted trajectories for their own collision avoidance planning.

Specifically, we utilize a global time base $t_{\text{now}}$ and trajectory sampling offset time $\tau_f^{(i,j)}$ to calculate the positions $\mathcal{G}^{n}(t_{\text{now}},\tau_f^{(i,j)})$ of other agents based on their committed trajectories. Then we introduce a penalty as follows:
\begin{equation}
\label{eq:ps}
\begin{aligned}
&\mathcal{P}_s\left(\mathbf{p}_i(\alpha_j\tau_i),\tau^{(i,j)}_f\right) = \sum_{n\neq \varkappa}
\phi\left(d_s^2 - d_n^2\right),\\[4pt]
&d_n^2=\|\mathbf{p}_i(\alpha_j\tau_i) -\mathcal{G}^n(t_{now},\tau^{(i,j)}_f)\|^2 
\end{aligned}
\end{equation}
Where $n$ denotes any agent other than $\varkappa$, $d_s$ is the safety distance threshold. 

\textit{5) Total Time $J_t$}: A key consideration for trajectory optimization to balance smooth and aggressiveness is minimizing the total time cost, which is defined as follows:
\begin{equation}
    J_t = \sum_{i=1}^{M} \tau_i \,\, ,  \frac{\partial J_t}{\partial \mathbf{c}_i} = 0 \,\, ,
    \frac{\partial J_t}{\partial \tau_i} = 1
\end{equation}

\subsection{Global Path Multi-Homotopy Topology}
As shown in Fig.\ref{fig:homotopy_demo}, in cluttered environments, two continuous trajectories are \emph{homotopic} if one can be smoothly deformed into the other without crossing obstacles or altering endpoints; otherwise they belong to different \emph{homotopy classes}.

\begin{figure}[tbp]
    \centering
    \includegraphics[trim=30 40 60 35, clip,width=0.8\linewidth]{Figure/Homotopy_Classes.pdf}
    \caption{Four representative homotopy classes (A–D) between the same endpoints.}
    \label{fig:homotopy_demo}
\end{figure}

Our motion camouflage reparameterization relies on a virtual prey path $\mathbf{p}_{\text{prey}}$ generated by a front-end planner. To mitigate local minima in non-convex optimization, we employ multi-homotopy path topology into the front-end planning and then parallel optimize different prey path to select the optimal solution.

The process begins by constructing a searchable sparse graph of the free space using methods like the Probabilistic Roadmap (PRM) or skeletonization (e.g., Apollonius diagram).

To filter redundant paths within the same class, we employ the H-signature: a lightweight integer vector that serves as a topological discriminator for a path relative to a set of obstacles.

Let a path $\gamma$ be represented by a sequence of vertices $z_k$, and each obstacle by a point $a_r$. For each obstacle, we compute its corresponding integer winding number $h_r(\gamma)$, which represents the net number of counter-clockwise turns the path makes around it.

This is calculated by summing the continuous angle changes for each path segment $(z_k, z_{k+1})$ relative to the obstacle $a_r$:
\begin{equation}
\begin{aligned}
    \Theta_r(\gamma) &= \sum_{k=0}^{K-1}\,\widetilde{\angle}\!\left(\frac{z_{k+1}-a_r}{\,z_k-a_r\,}\right), \\
    h_r(\gamma) &= \left\lfloor \dfrac{\Theta_r(\gamma)}{2\pi} \right\rceil.
\end{aligned}
\end{equation}
Here, $\widetilde{\angle}(\cdot)$ is the path-continuous argument function that accumulates angle changes without $2\pi$ jumps, and $\lfloor \cdot \rceil$ is the nearest-integer operator.

The H-signature of the path, $\mathbf{h}(\gamma)$, is the vector composed of these individual winding numbers for all $R$ obstacles:
\begin{equation}
    \mathbf{h}(\gamma) = (h_1(\gamma), h_2(\gamma), \dots, h_R(\gamma)).
\end{equation}
Thus, H-signature provide a direct method to distinguish between homotopy classes. In the three-dimensional setting, the essence of the H-signature is to generalize the point-based abstraction of obstacles in 2D to representing each obstacle as a spatial curve, and to determine whether two paths belong to different homotopy classes by evaluating the Gauss linking number or line-integral-based linkage of a closed path around that curve. This provides sound but not complete homotopy discrimination, following practical strategies adopted in topology-guided dynamic planning.


\section{Local Replanning under Spatiotemporal Topology}
\subsection{Triggering Conditions and Assumptions}
The agent obtains a high-quality, feasible global trajectory from the global planner described in the previous section. However, dynamic obstacles still exist in the environment. To ensure motion safety, a local replanning algorithm is required. We assume the agent can predict the trajectories of dynamic obstacles via sensors such as radar, which leads to our proposed method.

For compactness, we utilize the global time base $t_{now}$ and the future offset time $\delta$ to calculate the agent's global trajectory positions $\tilde{\mathbf{p}}_{g}(t_{now},\delta)$. Likewise, the predicted position of the $r$-th dynamic obstacle is $\tilde{\mathbf{p}}^r_{o}(t_{now},\delta)$.

We then check in real-time whether the trajectory will conflict with any dynamic obstacle $r$ within a forward time horizon $\mu_{pre}$:
\begin{equation}
\label{eq:trigger_condition}
\min_{\delta \in [0, \mu_{pre}]} \| \tilde{\mathbf{p}}_{g}(t_{now},\delta) - \tilde{\mathbf{p}}^r_o(t_{now},\delta) \| < d_s
\end{equation}
where $d_s$ is the prescribed safety margin. If condition (\ref{eq:trigger_condition}) is met, meaning a collision risk is predicted within the next $\mu_{pre}$ time, the local replanning is triggered.

In practice, computing the distance over a continuous time offset is computationally expensive. We approximate this check by discretely sampling time offsets $\Delta t$ at a sufficiently high resolution within the time horizon $[0, \mu_{pre}]$ and evaluating the minimum distance over these sample points.

\subsection{Local Objective and Dynamic-Obstacle Penalty}
If the local planner is activated, it will generate a new trajectory $\mathbf{p}_{\text{L}}(t)$ that avoids the predicted collision while remaining as close as possible to the original global path.
This problem is formulated as an optimization that re-uses the efficient motion camouflage parameterization that is introduced in Sec.~\ref{sec:global_planner}.

First, we should specify the boundary conditions of the optimization problem. The initial state is set to the agent's current state at the moment $t_{\sigma}$ when the local planner is triggered, and the terminal state is "anchored" to the original global trajectory.
\begin{equation}
\begin{aligned}
    &\bar{\mathbf{p}}_0 = \tilde{\mathbf{p}}^{(0:s-1)}_{g}(t_{\sigma},0) \\ 
    &\bar{\mathbf{p}}_f = \tilde{\mathbf{p}}_g^{(0:s-1)}(t_{\sigma},\mu)
\end{aligned}
\end{equation}
Where $\mu$ is the time horizon for the local replanning, and is set larger than the prediction window $\mu_{pre}$ to ensure sufficient time to smoothly navigate around obstacles and rejoin the global path. The objective function for the local problem is structured similarly to the global objective \eqref{eq:unconstrained_problem}, but with added penalty and modified time-cost term.

The new penalty term $\mathcal{P}_d$ is for the dynamic obstacles avoidance. It is formulated analogously to the inter-agent collision avoidance term \eqref{eq:ps} and leverages the absolute time $\tau^{(i,j)}_f$ to query the predicted position of dynamic obstacles $\tilde{\mathbf{p}}^r_o(t_{now},\tau^{(i,j)}_f)$ at each sampled point along the local trajectory.
\begin{equation} 
\label{eq:pd}
\begin{aligned}
&\mathcal{P}_d\left(\mathbf{p}_i(\alpha_j\tau_i),\tau^{(i,j)}_f\right) = \sum_{r=1}^{R_d} \phi\left(d_s^2 - d_r^2\right),\\[4pt]
&d_r^2=\|\mathbf{p}_i(\alpha_j\tau_i) -\tilde{\mathbf{p}}^r_o(t_{now},\tau^{(i,j)}_f)\|^2
\end{aligned}
\end{equation}
where $R_d$ is the number of relevant dynamic obstacles; the gradient calculation follows the same logic as \eqref{eq:abs_time_term}.

To encourage the duration of the local trajectory closely matches the time horizon $\mu$,  we replace the simple linear time cost $J_t$ with the following soft constraint:
\begin{equation}
\label{eq:local_J_t}
J_t^l = \left| \sum^{M}_{i=1}\tau_i - \mu \right|^3
\end{equation}
The gradients with respect to $\mathbf{c}_i$ and $\tau_i$ are:
\begin{equation}
    \frac{\partial J_t^l}{\partial \mathbf{c}_i} = 0,
    \frac{\partial J_t^l}{\partial \tau_i} = 3(\sum^{M}_{i=1}\tau_i - \mu)^2 \cdot \text{sgn}(\sum^{M}_{i=1}\tau_i - \mu)
\end{equation}
Finally, a safety protocol is enforced after the local optimization converges. We define a maximum permissible time window $T_{\epsilon}$, if the duration of the local trajectory exceeds this window,
\begin{equation}
\sum_{i=1}^{M}\tau_i > T_{\epsilon},
\end{equation}
the agent will still execute the computed local trajectory $\mathbf{p}_{\text{L}}(t)$ to ensure dynamic collision avoidance. However, during the execution of this local trajectory, the global planner described in Sec.~\ref{sec:global_planner} is asynchronously triggered.

\subsection{Homotopy Approximation via 3D Spatiotemporal Projections}
Local optimization also requires a virtual prey path. However, different from the global topology, the local planner must handle topology in a dynamic environment.

To address this, we adopt and generalize the topology-driven concept from De Groot et al.\cite{DeGroot2025TMPC} This approach handles moving obstacles by incorporating time into the state space. Fig.\ref{fig:local_topo_prm} illustrates this concept using the $d=2$ case. 

\begin{figure}[tbp]
    \centering
    \includegraphics[trim=40 20 12 12, clip,width=0.8\linewidth]{Figure/PRM.pdf}
    \caption{Dynamic obstacles are represented as static "cylinders" in the 2D+Time state space. A sampling-based planner finds multi-homotopy paths (e.g., 1, 2, 3, 4)}
    \label{fig:local_topo_prm}
\end{figure}

While the implementation in \cite{DeGroot2025TMPC} focused on 2D, the principles of sampling-based search and topological analysis can extend to higher dimensions.

For the $d=3$ case, we construct a simplified spatiotemporal state space $\mathcal{X}:=\mathbb{R}^{3}\times[0, \mu]$, where $\mu$ is our local planning horizon.

In this 4-dimensional state space, the predicted future motion of dynamic obstacles are treated as static hyper-tubes.

Finding paths in this space using PRM is algorithmically feasible, the challenge lies in distinguishing different homotopy classes. H-signature in a 4D space is computationally complex and challenging for real-time applications.

Therefore, we adopt a practical approximate method. We project the 4D paths and obstacle hyper-tubes onto three distinct 3D spatiotemporal subspaces: $(\text{x, y, t})$, $(\text{x, z, t})$, and $(\text{y, z, t})$. We then compute the H-signature for any two paths independently in each of these three projections. If the H-signature differ between the two paths in any of these three projections, we consider them to be in different homotopy classes.

We acknowledge that this method, designed for computational simplicity, has inherent limitations and cannot fully distinguish all homotopy classes. However, for our multi-homotopy path optimization scenario, this approximation is acceptable.

\begin{proposition}[Soundness of the 3D projection test]
Let $X=\mathbb{R}^3\times[0,\mu]$. Obstacles $O\subset X$, free space $F=X\setminus O$. A causal path is a continuous map $\gamma:[0,1]\to F$ with nondecreasing time. Denote the coordinate projections $\pi_{xyt},\pi_{xzt},\pi_{yzt}$ and the projected free spaces $F_\alpha=\pi_\alpha(F)$. On each $F_\alpha$ we compute an H-signature $h_\alpha$ that separates endpoint-fixed homotopy classes along the region we traverse.

For two causal paths $\gamma_1,\gamma_2$ with the same endpoints, if there exists $\alpha\in\{xyt,xzt,yzt\}$ such that
\[
h_\alpha(\pi_\alpha\circ\gamma_1)\neq h_\alpha(\pi_\alpha\circ\gamma_2),
\]
then $\gamma_1$ and $\gamma_2$ are not homotopic in $F$.
\end{proposition}

\begin{proof}
The projection $\pi_\alpha$ induces a map on endpoint-fixed homotopy classes. If $\gamma_1$ and $\gamma_2$ were homotopic in $F$, then $\pi_\alpha\circ\gamma_1$ and $\pi_\alpha\circ\gamma_2$ would be homotopic in $F_\alpha$, hence their H-signature would coincide.
\end{proof}

\begin{remark}[Implementation Note]
In practice we use obstacle shadows $\widetilde F_\alpha=\mathbb{R}^3\setminus\pi_\alpha(O)$. This is conservative and keeps the proposition sound when the compared curves have clearance $c>0$ to $\partial\widetilde F_\alpha$. A sufficient sampling rule in time: if the spatial motion is $L$-Lipschitz, choose step $\Delta t$ with $L\,\Delta t<c$.
\end{remark}

\begin{remark}[Limitation]
The test is not complete: equal signatures in all three projections does not guarantee equivalence in 4D. We treat it as a certificate of difference.
\end{remark}

\section{Experiments and Results}
\label{sec:experiments}
This section presents the validation of our algorithm through both simulation and real-world experiments, accompanied by a systematic quantitative analysis of the outcomes.

\subsection{Implementation Setup}
\label{subsec:setup}
All simulations were performed on a workstation equipped with an Intel Core i7-14650HX CPU (2.2GHz). This environment utilized two software platforms: numerical simulations were run in MATLAB 2023b, while system-level simulations were conducted using ROS2-Humble. For real-world experiments, the experimental platform was a UGV equipped with a Raspberry Pi 4 and an M10P lidar, and the entire physical setup also operated on the ROS2-Humble.

\subsection{Simulation Experiments}
To validate the effectiveness of our proposed algorithm's dimensionality reduction, we first conducted a numerical comparison between our MOCHA algorithm and the MINCO algorithm within MATLAB. The experiments were set in two representative static environments: a 2D environment with circular obstacles and a 3D forest environment with cylindrical obstacles. 

In our experiments, the trajectories were uniformly discretized with a segment length of $1\,\mathrm{m}$, and each segment contained $\kappa = 20$ sampling points. The optimization weights were set as follows: the smoothness (energy) term $w_e = 1$, the temporal regularization term $w_t = 1$, the obstacle avoidance penalty $w_o = 100$, and the dynamic feasibility penalty $w_d = 100$. For both MOCHA and MINCO, the dynamic constraints were consistently enforced with $v_{\max}=12\,\mathrm{m/s}$ and $a_{\max}=5\,\mathrm{m/s}^2$. All optimization problems were solved using \textit{fminunc}.

Fig.~\ref{fig:Map1_t} and Fig.~\ref{fig:Map2_t} show that both MOCHA and MINCO successfully generate smooth and collision-free trajectories in the 2D and 3D environments, respectively. The corresponding dynamic profiles in Fig.~\ref{fig:Map1_d} and Fig.~\ref{fig:Map2_d} confirm that all trajectories strictly satisfy the imposed dynamic limits.
\begin{figure}[tbp]
    \centering
    \begin{subfigure}[b]{0.8\linewidth}
        \centering
        \includegraphics[width=1.0\linewidth]{Figure/Map_I/Map1_T.pdf}
        \caption{Trajectory comparison in the 2D environment.}
        \label{fig:Map1_t}
    \end{subfigure}
    
    \begin{subfigure}[b]{0.8\linewidth}
        \centering
        \includegraphics[width=1.0\linewidth]{Figure/Map_Ⅱ/MAP2_T.pdf}
        \caption{Trajectory comparison in the 3D environment.}
        \label{fig:Map2_t}
    \end{subfigure}
    \caption{Trajectories generated by MOCHA and MINCO in 2D (a) and 3D (b) environments.}
    \label{fig:All_t}
\end{figure}

\begin{figure}[tbp]
    \centering
    \begin{subfigure}[b]{0.8\linewidth}
        \centering
        \includegraphics[width=1.0\linewidth]{Figure/Map_I/2D_d.pdf}
        \caption{Dynamic profiles for the 2D trajectories.}
        \label{fig:Map1_d}
    \end{subfigure}
    
    \begin{subfigure}[b]{0.8\linewidth}
        \centering
        \includegraphics[width=1.0\linewidth]{Figure/Map_Ⅱ/3D_d.pdf}
        \caption{Dynamic profiles for the 3D trajectories.}
        \label{fig:Map2_d}
    \end{subfigure}
    \caption{Dynamic profiles for the trajectories in 2D (a) and 3D (b) environments, confirming adherence to dynamic constraints.}
    \label{fig:Matlab_t}
\end{figure}
The specific quantitative results of the optimization are summarized in Table~\ref{tab:matlab}. In the 2D scenario, our MOCHA algorithm reduced the planning time by $25.9\%$ while maintaining nearly identical trajectory quality. The computational advantage was even more pronounced in the 3D scenario, where our algorithm achieved a reduction of $28.4\%$ in planning time. It is worth noting that in the 3D case (Table~\ref{tab:matlab}), MOCHA's trajectory quality ($J=494.34$) is slightly lower than that of MINCO ($J=419.06$). Specifically, MOCHA yields a slightly longer trajectory length (increased by $\approx 1.65\%$) and a slower arrival time (increased by $\approx 10.0\%$), which represents a reasonable trade-off for its significantly reduced optimization runtime.

This is an expected trade-off: by reducing the high dimensional waypoint search space to a single dimension, our method makes a small sacrifice in trajectory optimality in exchange for a significant gain in computational speed. As subsequent comparisons show, this trajectory quality remains significantly superior to other SOTA(state-of-the-art) algorithms. Therefore, the experimental results demonstrate the effectiveness of our algorithm's dimensionality reduction.
\begin{table}[tbp]
\centering
\caption{Validation of Dimensionality Reduction Effectiveness.}
\label{tab:matlab}
\begin{tabular}{lcccc}
\toprule
Method & $t_{\text{plan}}$ (s) & $T$(s) & $L$ (m) & $J$ \\
\midrule
MOCHA(2D) & \textbf{1.86}  & \textbf{17.51} & \textbf{146.24} & \textbf{409.57} \\ 
MINCO(2D) & 2.51  & 17.15 & 146.89 & 400.12 \\ 
MOCHA(3D) & \textbf{1.74}  & \textbf{21.11} & \textbf{178.3} & \textbf{494.34} \\ 
MINCO(3D) & 2.43  & 19.19 & 175.4 & 419.06 \\ 
\bottomrule
\end{tabular}
\end{table}

Subsequently, and prior to real-world validation, we deployed our complete planning framework—comprising the front-end topologizer and the MOCHA local planner—within the ROS2-Humble environment. Specifically, for 2D global planning, our front-end topologizer utilizes an H-signature topology check on a skeleton graph generated from an Apollonius diagram, which is highly efficient in 2D. For local replanning, the front-end topology is generated using a Probabilistic Roadmap (PRM). To evaluate the system in this more realistic setting, we benchmarked it against two other SOTA planners: TRR~\cite{gao2020teach} and SST~\cite{bekris2021asymptotically}. 

This selection provides a comprehensive comparison: TRR, much like our method, is an iterative spatio-temporal optimization algorithm, while SST is a prominent discrete sampling-based algorithm. The experiment was conducted in an environment with dozens of obstacles. For this simulation, the robot radius was set to 0.3m, and the dynamic limits were set to $v_{\max}=3$ m/s and $a_{\max}=2$ m/s$^2$. We selected three different goal locations for comparison to comprehensively evaluate performance.

\begin{figure}[tbp]
    \centering
    \begin{subfigure}[b]{0.8\linewidth}
        \centering
        \includegraphics[trim=10 5 10 10, clip, width=\linewidth]{Figure/Compare/target1/dynamics.pdf}
        \caption{Target 1}
        \label{fig:Com1_d}
    \end{subfigure}
    % Target 2
    \begin{subfigure}[b]{0.8\linewidth}
        \centering
        \includegraphics[trim=10 5 10 10, clip, width=\linewidth]{Figure/Compare/target2/dynamics.pdf}
        \caption{Target 2}
        \label{fig:Com2_d}
    \end{subfigure}
    % Target 3
    \begin{subfigure}[b]{0.8\linewidth}
        \centering
        \includegraphics[trim=10 5 10 10, clip, width=\linewidth]{Figure/Compare/target3/dynamics.pdf}
        \caption{Target 3}
        \label{fig:Com3_d}
    \end{subfigure}
    \caption{Dynamics corresponding to the trajectories in Fig.~\ref{fig:All_Com_t}. MOCHA's velocity sustains a high average level, whereas TRR and SST are visibly more conservative, resulting in the longer flight times quantified in Table~\ref{tab:sota_comparison}.}
    \label{fig:All_Com_d}
\end{figure}

The trajectories in Fig.~\ref{fig:All_Com_t} and the dynamics profiles in Fig.~\ref{fig:All_Com_d} are quantitatively substantiated in Table~\ref{tab:sota_comparison}. 
\begin{table}[tbp]
\centering
\caption{Quantitative Comparison with SOTA Planners across Three Different Targets.}
\label{tab:sota_comparison}
\begin{tabular}{llccccc}
\toprule
Target & Method & \makecell{$t_{\text{plan}}$ \\ (s)} & \makecell{$L$ \\ (m)} & \makecell{T \\ (s)} & \makecell{$v_{\max}$ \\ (m/s)} & \makecell{$v_{avg}$ \\ (m/s)} \\
\midrule
\multirow{3}{*}{Target 1} 
 & MOCHA & \textbf{0.029} & \textbf{144.57} & \textbf{68.45} & \textbf{3.00} & \textbf{2.11} \\
 & TRR   & 0.187          & 145.80          & 108.93          & 2.14          & 1.38 \\
 & SST   & 1.506          & 177.97          & 103.05          & 2.99          & 1.72 \\
\midrule
\multirow{3}{*}{Target 2} 
 & MOCHA & \textbf{0.026} & \textbf{114.67} & \textbf{50.48} & \textbf{3.00} & \textbf{2.27} \\
 & TRR   & 0.229          & 113.04          & 81.79           & 2.11          & 1.38 \\
 & SST   & 1.071          & 159.39          & 93.65           & 2.94          & 1.71 \\
\midrule
\multirow{3}{*}{Target 3} 
 & MOCHA & \textbf{0.023} & \textbf{93.21} & \textbf{41.03} & \textbf{2.98} & \textbf{2.27} \\
 & TRR   & 0.048          & 91.11           & 66.82           & 2.34          & 1.36 \\
 & SST   & 1.059          & 115.96          & 69.75           & 2.96          & 1.66 \\
\bottomrule
\end{tabular}
\end{table}
MOCHA's planning time $t_{\text{plan}}$ of 23--29~ms is exceptionally efficient, proving up to 8.8$\times$ faster than TRR (48--229~ms) and consistently over an order of magnitude (36$\times$--51$\times$) faster than SST (1059--1506~ms). This computational speed, enabled by our motion camouflage reparameterization. MOCHA achieves the shortest total flight time ($T$) in all scenarios, completing tasks 37--39\% faster than TRR and 34--46\% faster than SST. This is achieved by generating aggressive trajectories with the highest average velocity $v_{avg}$ (avg. 2.22~m/s vs TRR's 1.37~m/s) while adhering to $v_{\max}$ limits and maintaining competitive path lengths $L$.

\begin{figure*}[tbp]
    \centering
    % Target 1
    \begin{subfigure}[b]{0.32\linewidth}
        \centering
        \includegraphics[trim=10 10 10 10, clip, width=\linewidth]{Figure/Compare/target1/trajectory.pdf}
        \caption{Target 1 }
        \label{fig:Com1_t}
    \end{subfigure}
    % Target 2
    \begin{subfigure}[b]{0.32\linewidth}
        \centering
        \includegraphics[trim=10 10 10 10, clip, width=\linewidth]{Figure/Compare/target2/trajectory.pdf}
        \caption{Target 2 }
        \label{fig:Com2_t}
    \end{subfigure}
    % Target 3
    \begin{subfigure}[b]{0.32\linewidth}
        \centering
        \includegraphics[trim=10 10 10 10, clip, width=\linewidth]{Figure/Compare/target3/trajectory.pdf}
        \caption{Target 3 }
        \label{fig:Com3_t}
    \end{subfigure}
    \caption{Comparison of resulting trajectories from all three methods. MOCHA (ours) consistently finds smooth, efficient, and direct paths to the goal. TRR first constructs safe flight corridors and then performs iterative spatio-temporal optimization within them. SST explores the space and often produces paths that are noticeably longer and less direct.}
    \label{fig:All_Com_t}
\end{figure*}

\subsection{Advanced features}
Finally, we evaluate the advanced features of MOCHA: local replanning for dynamic obstacles and multi-agent scalability.

We first test the local replanning module, as demonstrated in Figure~\ref{fig:local_avoidance_sub}. In this scenario, the agent first plans a global trajectory (shown as the dashed blue line) and begins execution. During its movement, it continuously checks for potential conflicts with dynamic obstacles within a forward prediction horizon of $\mu_{pre}=3s$. 
\begin{figure}[tbp]
    \centering
    \includegraphics[trim=22 22 22 22, clip,width=0.8\linewidth]{Figure/Local/avoidance.pdf}
    \caption{Local replanning maneuver for a dynamic obstacle. The agent, while following its global path, detects a conflict with an obstacle. It triggers a local planner to generate a new avoidance trajectory  that rejoins the global path at a future anchor point.}
    \label{fig:local_avoidance_sub} 
\end{figure}

As visualized in Fig.~\ref{fig:local_avoidance_sub}, upon detecting a collision risk with an approaching dynamic obstacle (orange circle), the local planner is triggered. It generates a new, smooth avoidance trajectory (solid red line) to safely navigate around the obstacle. This local trajectory is optimized to rejoin the original global path at a future "anchor point" (red square), which is set at $\mu=5s$ along the global path from the moment of replanning. The corresponding clearance data in Fig.~\ref{fig:Local_distance_sub} quantitatively validates this behavior. It confirms that the agent maintains a safe distance from all obstacles (both static and the moving one), and crucially, the clearance never drops below the safety threshold.

\begin{figure}[tbp]
    \centering
    \includegraphics[trim=10 10 10 28, clip,width=0.8\linewidth]{Figure/Local/distance.pdf}
    \caption{Obstacle clearance data for the maneuver in Figure~\ref{fig:local_avoidance_sub}. The plot shows the agent's minimum distance to the nearest obstacle over time, confirming it remains safely above the collision threshold throughout the avoidance.}
    \label{fig:Local_distance_sub} 
\end{figure}

We demonstrate the scalability of our framework by simulating 5 agents navigating to distinct goals in the same cluttered environment. Specifically, we placed the agents at nearby starting coordinates - (0,0), (2,0), (0,2), (4,0) and (0,4) - and assigned them distinct randomly generated goal locations, as shown in Fig.~\ref{fig:Multi_trajectories}. 

The effectiveness of our inter-agent collision avoidance penalty is proven in Fig.~\ref{fig:inter_distances}. The dashed line in the figure represents the set safety distance of 0.8m, which includes an additional 0.2m safety margin on top of the 0.6m minimum separation (twice the robot radius) to mitigate potential communication and planning delays. The plot confirms that all inter-agent distances remained safely above this 0.8m threshold throughout their entire motion.
\begin{figure}[tbp]
    \centering
    \includegraphics[trim=22 25 22 28, clip,width=0.9\linewidth]{Figure/Multi_agents/inter_distances.pdf}
    \caption{Inter-agent distances for the 5-agent simulation. The plot shows the minimum distance between all pairs of agents over time. The minimum safety distance (dashed red line) is respected by all agents, proving the effectiveness of the inter-agent collision avoidance penalty.}
    \label{fig:inter_distances}
\end{figure}

\begin{figure}[tbp]
    \centering
    \includegraphics[trim=10 10 10 20, clip,width=0.8\linewidth]{Figure/Multi_agents/trajectories.pdf}
    \caption{Multi-agent scalability demonstration. Five agents, starting from nearby locations, successfully generate safe and efficient trajectories to distinct goals in a cluttered environment using our distributed and asynchronous planning approach.}
    \label{fig:Multi_trajectories}
\end{figure}

Table~\ref{tab:multi_agent} further details the performance metrics for this test. In this context, $N$ represents the number of initial homotopy paths found by our front-end planner, and $t_{\text{plan}}$ is the \emph{total} time taken to optimize all these $N$ paths in parallel. The results show that the optimization time for any single trajectory is extremely low (e.g., for agent (0,0), 6 paths were optimized in parallel in just 0.027s). This multi-homotopy approach, combined with parallel optimization, effectively mitigates the problem of the optimizer getting trapped in local minima. This advantage is particularly evident given the scenario: the agents' start points are clustered closely together, as are their end points. A traditional, single-topology optimization algorithm would struggle to produce such diverse, high-quality, and collision-free trajectories. The data confirms the real-time performance and scalability of MOCHA.

\begin{table}[tbp]
\centering
\caption{Performance metrics for the 5-agent scalability test.}
\begin{tabular}{lccc}
\toprule
Start & $t_{\text{plan}}$ (s) & $N$ (Paths) & $D_{min}$ (m) \\ % Added units and clarity
\midrule % Use midrule for consistency
(0,0) & 0.027 & 6 & 1.002  \\
(2,0) & 0.053 & 6 & 1.002  \\
(0,2) & 0.052 & 6 & 0.969  \\
(4,0) & 0.079 & 5 & 2.001   \\
(0,4) & 0.083 & 5 & 0.969  \\
\bottomrule
\end{tabular}
\label{tab:multi_agent}
\end{table}

\subsection{Real-world Experiments}
To validate the practical applicability and robustness of the MOCHA framework, we conducted real-world experiments using two ground vehicles in a cluttered indoor environment, as shown in Fig.~\ref{fig:Initial_cost} and Fig.~\ref{fig:arrive}.

The experimental scene was set up in a long corridor, populated with 12 cylindrical obstacles with radii ranging from 36--44~cm. The MOCHA algorithm was deployed in a distributed manner on the two vehicles, which were equipped with LiDAR for indoor localization and real-time position acquisition. The agents used UDP to broadcast their committed trajectories to each other.

In the scenario depicted, the two agents (Agent 1 and Agent 2) start at nearby initial positions of $(0, 0)$ and $(-1, 0)$, respectively. They are tasked with navigating to two distinct, randomly selected goal points at the far end of the corridor. Both agents first perform multi-homotopy path planning to find several topologically distinct, feasible routes.

As shown in the top panel of Fig.~\ref{fig:Initial_cost}, Agent 1 first plans and finds multiple paths, selecting the one with the lowest cost (the pink path with cost 9.7) to execute. It commits to this trajectory and broadcasts it. Subsequently, Agent 2 performs its optimization. As shown in the bottom panel of Fig.~\ref{fig:Initial_cost}, Agent 2 also finds multiple paths. However, when calculating its costs, it incorporates Agent 1's committed trajectory via the inter-agent collision penalty $\mathcal{P}_s$. This significantly increases the cost of its yellow (15.1) and magenta (14.9) paths, which would otherwise conflict with Agent 1. As a result, Agent 2 selects the green path (cost 10.3), which provides a higher safety margin and is now the optimal choice.

Fig.~\ref{fig:arrive} shows a time-lapse of the successful execution of this plan. Agent 1 follows its chosen path, while Agent 2 executes the safe green path. Both vehicles successfully navigate the dense obstacle field and maintain safe separation, ultimately reaching their respective target points. This experiment demonstrates the effectiveness of our distributed, homotopy-aware framework in coordinating multiple agents safely and efficiently in a real-world, cluttered environment.

\begin{figure}[tbp]
    \centering
    \includegraphics[trim=10 50 10 80, clip,width=0.8\linewidth]{Figure/initial_cost.png}
    \caption{Real-world multi-agent experiment setup. \textbf{Top:} Agent 1 (further robot) computes multiple homotopy-aware paths, with the lowest cost path (pink, 9.7) selected. \textbf{Bottom:} Agent 2 (closer robot) computes its paths. Due to Agent 1's committed trajectory, the costs of conflicting paths (yellow, 15.1; magenta, 14.9) increase, leading Agent 2 to select the safer, non-conflicting green path (10.3).}
    \label{fig:Initial_cost}
\end{figure}

\begin{figure}[tbp]
    \centering
    \includegraphics[trim=65 200 65 200, clip,width=0.8\linewidth]{Figure/Arrive.png}
    \caption{Time-lapse of the real-world experiment execution. Agent 1 (following its chosen path, indicated in yellow) and Agent 2 (green path) execute their trajectories. Both agents successfully navigate the dense obstacle field and avoid each other, demonstrating the effectiveness of the distributed MOCHA framework.}
    \label{fig:arrive}
\end{figure}


\section{Discussion and Limitations}
In this work, we introduced MOCHA, a homotopy-aware trajectory planning framework that combines a motion camouflage–inspired reparameterization with multi candidate optimization to achieve fast and safe motion in dynamic and cluttered environments. Extensive simulation and real-world experiments demonstrate that the method significantly accelerates computation while maintaining smoothness, dynamic feasibility, and multi-agent scalability.

Despite these advantages, several limitations remain. First, the current dynamic-obstacle handling relies on deterministic constant-velocity predictions, which may lead to suboptimal behavior in highly interactive or uncertain scenarios. Second, our homotopy reasoning is based on three spatiotemporal projections rather than full 4D topology, providing efficiency but only approximate discriminability in complex 3D entanglements. Additionally, extremely aggressive maneuvers may require increased scalar resolution to ensure full expressiveness of the compressed representation.

In future work, we plan to incorporate probabilistic behavior prediction, explore more rigorous space–time homotopy characterizations, and develop adaptive parameterization strategies. We believe these enhancements will further strengthen MOCHA’s reliability and applicability in large-scale, real-world multi-agent deployment.

\bibliographystyle{IEEEtran}
\bibliography{references.bib}

\end{document}